"""
AIç¿»è¯‘æ¨¡å— - å°†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ç¿»è¯‘æˆç»“æ„åŒ–çš„å·¥å…·è°ƒç”¨
è¿™æ˜¯"å¤§è„‘"ï¼Œè´Ÿè´£ç†è§£ç”¨æˆ·æ„å›¾

Author: TJxiaobao
License: MIT
Version: 0.0.6
"""

from openai import OpenAI
from typing import List, Dict, Any, Optional
import json
import logging

from ..config.settings import config
from ..prompts.manager import get_prompt, get_all_tools, get_tools_by_names, get_tool_groups, get_routing_config
from ..models.ai_response import (
    AIResponse,
    create_tool_calls_response,
    create_clarification_response,
    create_help_response,
    create_friendly_message_response,
    create_task_list_response,
    create_error_response
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class AIUnderstandingError(Exception):
    """AI ç†è§£å¤±è´¥å¼‚å¸¸ - ç”¨äºè§¦å‘ä¸Šä¸‹æ–‡é‡è¯•æœºåˆ¶"""
    pass


class AITranslator:
    """AIç¿»è¯‘å™¨ - ä½¿ç”¨LLMçš„Function Callingèƒ½åŠ›
    
    æ–°å¢ï¼šä¸‰é˜¶æ®µ AI æ¶æ„
    - é˜¶æ®µ1ï¼šæ€»æŒ‡æŒ¥ï¼ˆCoordinatorï¼‰- æ‹†åˆ†å¤åˆæŒ‡ä»¤
    - é˜¶æ®µ2-3ï¼šè·¯ç”± + ä¸“å®¶ï¼ˆç°æœ‰é€»è¾‘ï¼‰
    """
    
    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None):
        """
        åˆå§‹åŒ–AIç¿»è¯‘å™¨
        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
            base_url: APIåŸºç¡€URLï¼Œæ”¯æŒå…¼å®¹OpenAIæ¥å£çš„æœåŠ¡
        """
        self.api_key = api_key or config.OPENAI_API_KEY
        self.base_url = base_url or config.OPENAI_API_BASE
        
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        
        # ç¦ç”¨OpenAI SDKçš„è‡ªåŠ¨é‡è¯•ï¼Œæˆ‘ä»¬è‡ªå·±æ§åˆ¶é‡è¯•é€»è¾‘
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
            max_retries=0  # â­ï¸ ç¦ç”¨è‡ªåŠ¨é‡è¯•
        )
        
        # æ™ºèƒ½é€‰æ‹©æ¨¡å‹
        self.model = self._select_model()
        logger.info(f"AIç¿»è¯‘å™¨åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨API: {self.base_url}")
        logger.info(f"ä½¿ç”¨æ¨¡å‹: {self.model}")
    
    def _select_model(self) -> str:
        """
        æ ¹æ® API Base URL æ™ºèƒ½é€‰æ‹©æ¨¡å‹
        Returns:
            æ¨¡å‹åç§°
        """
        if "moonshot" in self.base_url.lower():
            # Kimi / æœˆä¹‹æš—é¢
            return "moonshot-v1-8k"
        elif "deepseek" in self.base_url.lower():
            # DeepSeek
            return "deepseek-chat"
        else:
            # OpenAI æˆ–å…¶ä»–
            return "gpt-4o-mini"
    
    def _get_tool_groups(self) -> Dict[str, Any]:
        """è·å–å·¥å…·åˆ†ç»„é…ç½®"""
        try:
            return get_tool_groups()
        except:
            # å¦‚æœåŠ è½½å¤±è´¥ï¼Œè¿”å›ç©ºå­—å…¸
            logger.warning("âš ï¸ å·¥å…·åˆ†ç»„é…ç½®åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨æ‰€æœ‰å·¥å…·")
            return {}
    
    def _detect_tool_group(self, command: str) -> Optional[str]:
        """
        æ ¹æ®å…³é”®è¯æ£€æµ‹ç”¨æˆ·æŒ‡ä»¤å±äºå“ªä¸ªå·¥å…·ç»„
        Args:
            command: ç”¨æˆ·æŒ‡ä»¤
        Returns:
            å·¥å…·ç»„åç§°ï¼Œå¦‚æœæœªåŒ¹é…åˆ™è¿”å›None
        """
        command_lower = command.lower()
        tool_groups = self._get_tool_groups()
        
        for group_name, group_data in tool_groups.items():
            for keyword in group_data["keywords"]:
                if keyword in command_lower:
                    logger.info(f"å…³é”®è¯è·¯ç”±å‘½ä¸­: '{keyword}' â†’ {group_name} ç»„")
                    return group_name
        return None
    
    def get_tools_definition(self, filter_tools: Optional[List[str]] = None) -> List[Dict]:
        """
        è·å–å¯ç”¨çš„å·¥å…·ï¼ˆFunction Callingçš„schemaï¼‰
        è¿™æ˜¯å‘Šè¯‰AIå®ƒå¯ä»¥ä½¿ç”¨å“ªäº›å·¥å…·
        
        Args:
            filter_tools: å¯é€‰çš„å·¥å…·åç§°åˆ—è¡¨ï¼Œå¦‚æœæä¾›åˆ™åªè¿”å›è¿™äº›å·¥å…·
        
        æ³¨æ„ï¼šä¸ºäº†å…¼å®¹ä¸åŒçš„AIæœåŠ¡ï¼ˆKimiä¸æ”¯æŒæ•°ç»„ç±»å‹å®šä¹‰ï¼‰ï¼Œ
        è¿™é‡Œç»Ÿä¸€ä½¿ç”¨stringç±»å‹ï¼ŒAIä¼šè‡ªåŠ¨å¤„ç†æ•°å­—
        """
        # âœ… ä» YAML åŠ è½½ï¼Œä»£ç æåº¦å¹²å‡€ï¼
        if filter_tools:
            filtered = get_tools_by_names(filter_tools)
            logger.info(f"å·¥å…·è¿‡æ»¤ï¼šä½¿ç”¨ {len(filtered)} ä¸ªå·¥å…·")
            logger.info(f"å½“å‰ä½¿ç”¨å·¥å…·: {[t['function']['name'] for t in filtered]}")
            return filtered
        
        all_tools = get_all_tools()
        logger.info(f"ä½¿ç”¨æ‰€æœ‰å·¥å…·ï¼š{len(all_tools)} ä¸ª")
        return all_tools

    def build_system_prompt(self, headers: List[str], expert_type: str = None) -> str:
        """
        æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆåŸºç¡€ä¿¡æ¯ + ä¸“å®¶æç¤ºè¯ï¼‰
        Args:
            headers: ç”¨æˆ·è¡¨æ ¼çš„åˆ—ååˆ—è¡¨
            expert_type: ä¸“å®¶ç±»å‹ï¼ˆå¡«å……/æ•°å­¦/æ¸…æ´—ç­‰ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™åªè¿”å›åŸºç¡€æç¤ºè¯
        Returns:
            ç³»ç»Ÿæç¤ºè¯
        """
        # â­ï¸ ä½¿ç”¨æ–°çš„é€šç”¨åŸºç¡€æç¤ºè¯ï¼Œè¯´æ˜è¡¨æ ¼åˆ—åå’ŒåŸºæœ¬è§„åˆ™
        base_prompt = get_prompt('system_prompts.general_base', headers=', '.join(headers))
        
        # å¦‚æœæŒ‡å®šäº†ä¸“å®¶ç±»å‹ï¼Œè¿½åŠ ä¸“å®¶æç¤ºè¯
        if expert_type:
            expert_prompt = get_prompt(f'system_prompts.{expert_type}_expert')
            return base_prompt + "\n\n" + expert_prompt
        
        return base_prompt
    
    def _is_complex_command(self, command: str) -> bool:
        """
        æ™ºèƒ½åˆ¤æ–­æ˜¯å¦æ˜¯å¤åˆæŒ‡ä»¤ï¼ˆéœ€è¦æ€»æŒ‡æŒ¥æ‹†åˆ†ï¼‰
        
        Args:
            command: ç”¨æˆ·è¾“å…¥çš„æŒ‡ä»¤
        
        Returns:
            True å¦‚æœæ˜¯å¤åˆæŒ‡ä»¤ï¼ŒFalse å¦‚æœæ˜¯ç®€å•æŒ‡ä»¤
        """
        # ä» YAML åŠ è½½å¤åˆæŒ‡ä»¤æ ‡è®°
        routing_config = get_routing_config()
        complex_markers = routing_config.get('complex_markers', [])
        
        command_lower = command.lower()
        
        for marker in complex_markers:
            if marker.lower() in command_lower:
                logger.info(f"ğŸ” æ£€æµ‹åˆ°å¤åˆæŒ‡ä»¤æ ‡è®°: '{marker}'")
                return True
        
        # ç®€å•æŒ‡ä»¤ï¼ˆé•¿åº¦ < 50 ä¸”æ²¡æœ‰ç‰¹å¾ï¼‰
        if len(command) < 50:
            logger.info("âœ… æŒ‡ä»¤è¾ƒçŸ­ä¸”æ— å¤åˆç‰¹å¾ï¼Œåˆ¤å®šä¸ºç®€å•æŒ‡ä»¤")
            return False
        
        logger.info("âš ï¸  æŒ‡ä»¤è¾ƒé•¿ï¼Œèµ°æ€»æŒ‡æŒ¥è·¯å¾„ä»¥ç¡®ä¿å‡†ç¡®")
        return True
    
    def _is_contextual_command(self, command: str, history: List[Dict[str, str]] = None) -> bool:
        """
        æ™ºèƒ½åˆ¤æ–­æ˜¯å¦æ˜¯ä¾èµ–ä¸Šä¸‹æ–‡çš„æŒ‡ä»¤ï¼ˆå¢å¼ºç‰ˆï¼‰
        
        Args:
            command: ç”¨æˆ·è¾“å…¥çš„æŒ‡ä»¤
            history: å†å²å¯¹è¯è®°å½•
        
        Returns:
            True å¦‚æœä¾èµ–ä¸Šä¸‹æ–‡ï¼ŒFalse å¦‚æœä¸ä¾èµ–
        """
        # ä» YAML åŠ è½½ä¸Šä¸‹æ–‡ä¾èµ–æ ‡è®°
        routing_config = get_routing_config()
        contextual_markers = routing_config.get('contextual_markers', [])
        
        command_lower = command.lower()
        
        # 1. æ£€æŸ¥å¼ºåˆ¶ä¸Šä¸‹æ–‡æ ‡è®°ï¼ˆä»£è¯ï¼‰
        for marker in contextual_markers:
            if marker.lower() in command_lower:
                logger.info(f"ğŸ” æ£€æµ‹åˆ°ä¸Šä¸‹æ–‡ä¾èµ–æ ‡è®°: '{marker}'")
                return True
        
        # 2. â­ï¸ æ–°å¢ï¼šå»¶ç»­æ€§è¯æ±‡æ£€æµ‹
        continuation_markers = ["ä¹Ÿ", "è¿˜", "å†", "åŒæ ·", "ä¸€æ ·", "ç»§ç»­", "æ¥ç€", "å¦å¤–", "åŒæ—¶"]
        for marker in continuation_markers:
            if marker in command:
                logger.info(f"ğŸ” æ£€æµ‹åˆ°å»¶ç»­æ€§è¯æ±‡: '{marker}'")
                return True
        
        # 3. â­ï¸ æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨æ–­ï¼šå¦‚æœæŒ‡ä»¤åŒ…å«å¼•å·ï¼Œå¾ˆå¯èƒ½åœ¨å¼•ç”¨åˆšæ‰çš„ç»“æœ
        import re
        quoted_terms = re.findall(r'["""](.*?)["""]', command)
        if quoted_terms and history and len(history) > 0:
            logger.info(f"ğŸ§  æ™ºèƒ½ä¸Šä¸‹æ–‡æ¨æ–­: æŒ‡ä»¤åŒ…å«å¼•ç”¨ '{quoted_terms[0]}'ï¼Œå¯èƒ½å¼•ç”¨å†å²ç»“æœ")
            return True
        
        # 4. â­ï¸ æ–°å¢ï¼šçŸ­æŒ‡ä»¤å€¾å‘æ£€æµ‹ï¼ˆæŒ‡ä»¤å¾ˆçŸ­æ—¶ï¼Œæ›´å¯èƒ½ä¾èµ–ä¸Šä¸‹æ–‡ï¼‰
        # é˜ˆå€¼è®¾ä¸º7ï¼šåƒ"æ”¹ä¸º10"ï¼ˆ4å­—ç¬¦ï¼‰ä¼šè¢«åˆ¤ä¸ºä¾èµ–ä¸Šä¸‹æ–‡ï¼Œä½†"æŠŠç¨ç‡è®¾ä¸º0.13"ï¼ˆ9å­—ç¬¦ï¼‰ä¸ä¼š
        # todo è¿‡äºç”Ÿç¡¬
        if len(command) < 7 and history and len(history) > 0:
            logger.info(f"ğŸ§  çŸ­æŒ‡ä»¤æ£€æµ‹: æŒ‡ä»¤é•¿åº¦ {len(command)} < 7ï¼Œå€¾å‘æºå¸¦ä¸Šä¸‹æ–‡")
            return True
        
        logger.info("âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾ä¸Šä¸‹æ–‡ä¾èµ–ç‰¹å¾")
        return False
    
    def _call_coordinator(self, command: str, history: List[Dict[str, str]] = None) -> Optional[List[str]]:
        """
        è°ƒç”¨æ€»æŒ‡æŒ¥ AI æ‹†åˆ†å¤åˆæŒ‡ä»¤
        
        Args:
            command: ç”¨æˆ·çš„å¤åˆæŒ‡ä»¤
            history: å†å²å¯¹è¯è®°å½•ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ‹†åˆ†åçš„æŒ‡ä»¤åˆ—è¡¨ï¼Œå¦‚æœæ‹†åˆ†å¤±è´¥è¿”å› None
        """
        try:
            logger.info("ğŸ¯ è°ƒç”¨æ€»æŒ‡æŒ¥ï¼ˆCoordinatorï¼‰æ‹†åˆ†æŒ‡ä»¤")
            
            # ä» YAML åŠ è½½æ€»æŒ‡æŒ¥çš„ prompt å’Œ tools
            coordinator_prompt = get_prompt('system_prompts.coordinator')
            coordinator_tools = get_tools_by_names(['execute_tasks_in_order'])
            
            # æ„é€ æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«å†å²ï¼‰
            messages = [{"role": "system", "content": coordinator_prompt}]
            
            if history:
                logger.info(f"ğŸ“š æ³¨å…¥å†å²ä¸Šä¸‹æ–‡ï¼Œå…± {len(history)} æ¡æ¶ˆæ¯")
                messages.extend(history)
            
            messages.append({"role": "user", "content": command})
            
            # è¾“å‡ºå®Œæ•´çš„ AI è¯·æ±‚æ—¥å¿—
            logger.info("=" * 60)
            logger.info("ğŸ“¤ AI è¯·æ±‚ (Coordinator)")
            logger.info(f"Model: {self.model}")
            logger.info(f"Messages: {json.dumps(messages, ensure_ascii=False, indent=2)}")
            logger.info("=" * 60)
            
            # è°ƒç”¨ AI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=coordinator_tools,
                tool_choice={
                    "type": "function",
                    "function": {"name": "execute_tasks_in_order"}
                }  # å¼ºåˆ¶è°ƒç”¨æŒ‡å®šå·¥å…·ï¼Œä¸å…è®¸æ–‡æœ¬å›å¤
            )

            message = response.choices[0].message
            
            # è¾“å‡º AI å“åº”æ—¥å¿—
            logger.info("=" * 60)
            logger.info("ğŸ“¥ AI å“åº” (Coordinator)")
            logger.info(f"Finish Reason: {response.choices[0].finish_reason}")
            logger.info(f"Has Tool Calls: {bool(message.tool_calls)}")
            if message.tool_calls:
                for tc in message.tool_calls:
                    logger.info(f"Tool: {tc.function.name}")
                    logger.info(f"Arguments: {tc.function.arguments}")
            logger.info("=" * 60)
            
            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†å·¥å…·
            if not message.tool_calls:
                logger.warning("æ€»æŒ‡æŒ¥æœªè°ƒç”¨å·¥å…·ï¼Œé™çº§ä¸ºå•ä¸€æŒ‡ä»¤å¤„ç†")
                return None
            
            # è§£æå·¥å…·è°ƒç”¨
            tool_call = message.tool_calls[0]
            if tool_call.function.name == "execute_tasks_in_order":
                args = json.loads(tool_call.function.arguments)
                tasks = args.get("tasks", [])
                
                if not tasks:
                    logger.warning("æ€»æŒ‡æŒ¥è¿”å›ç©ºä»»åŠ¡åˆ—è¡¨")
                    return None
                
                logger.info(f"ğŸ¯ ä»»åŠ¡æ‹†åˆ†æˆåŠŸï¼Œå…± {len(tasks)} ä¸ªå­ä»»åŠ¡:")
                for i, task in enumerate(tasks, 1):
                    logger.info(f"  {i}. {task}")
                
                return tasks
            else:
                logger.warning(f"æ€»æŒ‡æŒ¥è°ƒç”¨äº†é”™è¯¯çš„å·¥å…·: {tool_call.function.name}")
                return None
                
        except Exception as e:
            logger.error(f"æ€»æŒ‡æŒ¥è°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def _call_ai_router(self, command: str) -> Optional[str]:
        """
        è°ƒç”¨ AI è·¯ç”±æ¥å†³å®šå·¥å…·ç»„ï¼ˆä¸¤çº§è·¯ç”±çš„ç¬¬äºŒçº§ï¼‰
        
        Args:
            command: ç”¨æˆ·çš„æŒ‡ä»¤
        
        Returns:
            å·¥å…·ç»„åç§°ï¼ˆfilling/math/cleaning/text/date/structure/analysisï¼‰ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        try:
            logger.info("ğŸ¤– è°ƒç”¨ AI è·¯ç”±ï¼ˆå…³é”®è¯æœªå‘½ä¸­ï¼Œä½¿ç”¨ AI å…œåº•ï¼‰")
            
            # ä» YAML åŠ è½½è·¯ç”± AI çš„ prompt å’Œ tools
            router_prompt = get_prompt('system_prompts.router')
            router_tool_names = [
                'route_to_filling',
                'route_to_math',
                'route_to_cleaning',
                'route_to_text',
                'route_to_date',
                'route_to_structure',
                'route_to_analysis'
            ]
            router_tools = get_tools_by_names(router_tool_names)
            
            # æ„é€ æ¶ˆæ¯
            messages = [
                {"role": "system", "content": router_prompt},
                {"role": "user", "content": command}
            ]
            
            # è¾“å‡º AI è¯·æ±‚æ—¥å¿—
            logger.info("=" * 60)
            logger.info("ğŸ“¤ AI è¯·æ±‚ (Router)")
            logger.info(f"Model: {self.model}")
            logger.info(f"Command: {command}")
            logger.info("=" * 60)
            
            # è°ƒç”¨ AI
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=router_tools,
                tool_choice="required"  # å¼ºåˆ¶è°ƒç”¨å·¥å…·
            )
            
            message = response.choices[0].message
            
            # è¾“å‡º AI å“åº”æ—¥å¿—
            logger.info("=" * 60)
            logger.info("ğŸ“¥ AI å“åº” (Router)")
            logger.info(f"Finish Reason: {response.choices[0].finish_reason}")
            if message.tool_calls:
                tool_name = message.tool_calls[0].function.name
                logger.info(f"Tool: {tool_name}")
            logger.info("=" * 60)
            
            # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†å·¥å…·
            if not message.tool_calls:
                logger.warning("AI è·¯ç”±æœªè°ƒç”¨å·¥å…·")
                return None
            
            # è§£æå·¥å…·åï¼šroute_to_filling â†’ filling
            tool_call = message.tool_calls[0]
            tool_name = tool_call.function.name
            
            if tool_name.startswith("route_to_"):
                group_name = tool_name.replace("route_to_", "")
                logger.info(f"ğŸ¯ AI è·¯ç”±ç»“æœ: {group_name}")
                return group_name
            else:
                logger.warning(f"AI è·¯ç”±è¿”å›äº†é”™è¯¯çš„å·¥å…·: {tool_name}")
                return None
                
        except Exception as e:
            logger.error(f"AI è·¯ç”±è°ƒç”¨å¤±è´¥: {e}")
            return None
    
    def translate_single_task(self, user_command: str, headers: List[str], history: List[Dict[str, str]] = None) -> Dict[str, Any]:
        """
        å…¬å¼€æ–¹æ³•ï¼šç¿»è¯‘å•ä¸ªä»»åŠ¡ï¼ˆä¾›WebSocketè°ƒç”¨ï¼‰
        """
        return self._translate_single_task(user_command, headers, history)
    
    def _translate_single_task(self, user_command: str, headers: List[str], history: List[Dict[str, str]] = None) -> AIResponse:
        """
        ç¿»è¯‘å•ä¸ªä»»åŠ¡ä¸ºå·¥å…·è°ƒç”¨ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        è¿™æ˜¯åŸæ¥çš„ translate() é€»è¾‘ï¼Œç°åœ¨ä½œä¸ºå­å‡½æ•°è¢«æ–°çš„ translate() è°ƒç”¨
        
        Args:
            user_command: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆå•ä¸€ä»»åŠ¡ï¼‰
            headers: è¡¨æ ¼çš„åˆ—ååˆ—è¡¨
            history: å†å²å¯¹è¯è®°å½•
        Returns:
            AIResponse: ç»Ÿä¸€çš„å“åº”å¯¹è±¡
        """
        try:
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯å¸®åŠ©æŒ‡ä»¤
            help_keywords = ["å¸®åŠ©", "help", "ä½ èƒ½åšä»€ä¹ˆ", "æœ‰ä»€ä¹ˆåŠŸèƒ½", "æ€ä¹ˆç”¨", "åŠŸèƒ½åˆ—è¡¨"]
            if user_command.strip().lower() in help_keywords:
                logger.info("ç”¨æˆ·è¯·æ±‚å¸®åŠ©ä¿¡æ¯")
                # âœ… ä» YAML åŠ è½½ï¼Œä»£ç å¹²å‡€ï¼
                help_message = get_prompt('help_messages.main')
                return create_help_response(help_message)
            
            # â­ï¸ ä¸¤çº§è·¯ç”±ä¼˜åŒ– - å…³é”®è¯ä¼˜å…ˆï¼ŒAI å…œåº•
            # ç¬¬ä¸€çº§ï¼šå…³é”®è¯è·¯ç”±ï¼ˆå¿«é€Ÿï¼Œ0 å»¶è¿Ÿï¼‰
            detected_group = self._detect_tool_group(user_command)
            
            if detected_group:
                # å‘½ä¸­å…³é”®è¯ï¼Œåªä½¿ç”¨è¯¥ç»„çš„å·¥å…·
                tool_groups = self._get_tool_groups()
                filter_tools = tool_groups[detected_group]["tools"]
                tools = self.get_tools_definition(filter_tools=filter_tools)
                logger.info(f"âœ… ã€ç¬¬ä¸€çº§è·¯ç”±ã€‘å…³é”®è¯å‘½ä¸­: {detected_group}ï¼ŒTokené¢„è®¡å‡å°‘ 60-70%")
            else:
                # ç¬¬äºŒçº§ï¼šAI è·¯ç”±ï¼ˆæ™ºèƒ½å…œåº•ï¼‰
                logger.info("âš ï¸ ã€ç¬¬ä¸€çº§è·¯ç”±ã€‘å…³é”®è¯æœªå‘½ä¸­ï¼Œå¯åŠ¨ç¬¬äºŒçº§ AI è·¯ç”±")
                ai_routed_group = self._call_ai_router(user_command)
                
                if ai_routed_group:
                    # AI è·¯ç”±æˆåŠŸ
                    tool_groups = self._get_tool_groups()
                    filter_tools = tool_groups[ai_routed_group]["tools"]
                    tools = self.get_tools_definition(filter_tools=filter_tools)
                    logger.info(f"âœ… ã€ç¬¬äºŒçº§è·¯ç”±ã€‘AI è·¯ç”±æˆåŠŸ: {ai_routed_group}ï¼ŒTokené¢„è®¡å‡å°‘ 60-70%")
                else:
                    # AI è·¯ç”±ä¹Ÿå¤±è´¥ï¼Œé™çº§åˆ°æ‰€æœ‰å·¥å…·ï¼ˆæœ€åå…œåº•ï¼‰
                    tools = self.get_tools_definition()
                    logger.info("âš ï¸ ã€ç¬¬äºŒçº§è·¯ç”±ã€‘AI è·¯ç”±å¤±è´¥ï¼Œé™çº§ä½¿ç”¨å…¨é‡å·¥å…·")
            
            # æ„é€ æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«å†å²ï¼‰
            messages = [{"role": "system", "content": self.build_system_prompt(headers)}]
            
            if history:
                logger.info(f"ğŸ“š æ³¨å…¥å†å²ä¸Šä¸‹æ–‡ï¼Œå…± {len(history)} æ¡æ¶ˆæ¯")
                messages.extend(history)
            
            messages.append({"role": "user", "content": user_command})
            
            # è¾“å‡ºå®Œæ•´çš„ AI è¯·æ±‚æ—¥å¿—
            logger.info("=" * 60)
            logger.info("ğŸ“¤ AI è¯·æ±‚ (Single Task)")
            logger.info(f"Model: {self.model}")
            logger.info(f"Messages: {json.dumps(messages, ensure_ascii=False, indent=2)}")
            logger.info(f"Tools Count: {len(tools)}")
            logger.info("=" * 60)
            
            # è°ƒç”¨AI
            response = self.client.chat.completions.create(
                model=self.model,  # æ ¹æ®APIè‡ªåŠ¨é€‰æ‹©æ¨¡å‹
                messages=messages,
                tools=tools,
                tool_choice="auto"  # è®©AIè‡ªåŠ¨å†³ç”¨æ˜¯å¦ä½¿ç”¨å·¥å…·
            )
            
            message = response.choices[0].message
            
            # è¾“å‡º AI å“åº”æ—¥å¿—
            logger.info("=" * 60)
            logger.info("ğŸ“¥ AI å“åº” (Single Task)")
            logger.info(f"Finish Reason: {response.choices[0].finish_reason}")
            logger.info(f"Has Tool Calls: {bool(message.tool_calls)}")
            if message.tool_calls:
                for tc in message.tool_calls:
                    logger.info(f"Tool: {tc.function.name}")
                    logger.info(f"Arguments: {tc.function.arguments}")
            if message.content:
                logger.info(f"Content: {message.content}")
            logger.info("=" * 60)
            
            # â­ï¸ ä½¿ç”¨ç»Ÿä¸€çš„è½¬æ¢å™¨ï¼ˆæ–¹æ¡ˆ3ä¼˜åŒ–ï¼‰
            return AIResponse.from_openai_response(message)
            
        except Exception as e:
            error_msg = f"AIç¿»è¯‘å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return create_error_response(error_msg, error_code="TRANSLATION_FAILED")
    
    def translate(self, user_command: str, headers: List[str], history: List[Dict[str, str]] = None) -> List[AIResponse]:
        """
        ã€æ–°ã€‘ä¸»å…¥å£ï¼šç¿»è¯‘ç”¨æˆ·æŒ‡ä»¤ä¸ºå·¥å…·è°ƒç”¨åˆ—è¡¨
        
        å®ç°ä¸‰é˜¶æ®µ AI æ¶æ„ + æ™ºèƒ½åˆ†æµ + ä¸Šä¸‹æ–‡æ„ŸçŸ¥è·¯ç”±ï¼š
        1. æ™ºèƒ½åˆ¤æ–­ï¼šæ˜¯ç®€å•æŒ‡ä»¤è¿˜æ˜¯å¤åˆæŒ‡ä»¤ï¼Ÿæ˜¯å¦ä¾èµ–ä¸Šä¸‹æ–‡ï¼Ÿ
        2. ç®€å•æŒ‡ä»¤ + æ— ä¸Šä¸‹æ–‡ä¾èµ–ï¼šç›´æ¥èµ°å¿«é€Ÿè·¯å¾„ï¼ˆ_translate_single_taskï¼Œæ— historyï¼‰
        3. ç®€å•æŒ‡ä»¤ + æœ‰ä¸Šä¸‹æ–‡ä¾èµ–ï¼šèµ°å¿«é€Ÿè·¯å¾„ä½†å¸¦ä¸Š history
        4. å¤åˆæŒ‡ä»¤ï¼šèµ°æ€»æŒ‡æŒ¥è·¯å¾„ï¼ˆæ‹†åˆ† â†’ å¾ªç¯ç¿»è¯‘ï¼‰
        
        Args:
            user_command: ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ˆå¯èƒ½æ˜¯å•ä¸€æˆ–å¤åˆæŒ‡ä»¤ï¼‰
            headers: è¡¨æ ¼çš„åˆ—ååˆ—è¡¨
            history: å†å²å¯¹è¯è®°å½•ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æŒ‡ä»¤åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ª Dictï¼ŒåŒ…å« successã€tool_calls ç­‰
            æ ¼å¼ï¼š[{"success": True, "tool_calls": [...]}, ...]
        """
        try:
            logger.info(f"ğŸ“ æ”¶åˆ°æŒ‡ä»¤: {user_command}")
            
            # ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½åˆ¤æ–­æ˜¯å¦æ˜¯å¤åˆæŒ‡ä»¤
            is_complex = self._is_complex_command(user_command)
            
            # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½åˆ¤æ–­æ˜¯å¦ä¾èµ–ä¸Šä¸‹æ–‡
            is_contextual = self._is_contextual_command(user_command, history=history)
            
            # ç¬¬ä¸‰æ­¥ï¼šå†³ç­–è·¯ç”±
            if not is_complex and not is_contextual:
                # ã€è·¯å¾„ Aã€‘ç®€å•æŒ‡ä»¤ + æ— æ˜æ˜¾ä¸Šä¸‹æ–‡ä¾èµ–
                # â­ï¸ ä¼˜åŒ–ï¼šæºå¸¦æœ€è¿‘1è½®å†å²ï¼ˆè€Œä¸æ˜¯å…¨éƒ¨å†å²ï¼‰ï¼Œæé«˜å‡†ç¡®æ€§ä¸”æ§åˆ¶ Token
                recent_history = history[-2:] if history and len(history) >= 2 else history
                
                # æ”¹è¿›æ—¥å¿—ï¼šå³ä½¿æ˜¯ç©ºå†å²ä¹Ÿè¦è¯´æ˜ç­–ç•¥
                if recent_history and len(recent_history) > 0:
                    logger.info(f"ğŸš€ ã€è·¯å¾„ Aã€‘ç®€å•æŒ‡ä»¤ï¼Œæºå¸¦æœ€è¿‘1è½®å†å²ï¼ˆå…±{len(recent_history)}æ¡æ¶ˆæ¯ï¼‰")
                else:
                    logger.info("ğŸš€ ã€è·¯å¾„ Aã€‘ç®€å•æŒ‡ä»¤ï¼ˆé¦–æ¬¡è¯·æ±‚ï¼Œæ— å†å²ï¼‰â†’ åç»­å°†è‡ªåŠ¨æºå¸¦æœ€è¿‘1è½®")
                
                result = self._translate_single_task(user_command, headers, history=recent_history)
                return [result]
            
            elif not is_complex and is_contextual:
                # ã€è·¯å¾„ Bã€‘ç®€å•ä½†ä¾èµ–ä¸Šä¸‹æ–‡çš„æŒ‡ä»¤ï¼ˆå¦‚"æŠŠå®ƒä»¬æ”¹ä¸º0.1"ï¼‰
                logger.info(f"ğŸ§  ã€è·¯å¾„ Bã€‘ç®€å•æŒ‡ä»¤ + æ˜æ˜¾ä¾èµ–ä¸Šä¸‹æ–‡ï¼Œç›´æ¥ç¿»è¯‘ï¼ˆå¸¦å®Œæ•´ historyï¼Œå…±{len(history) if history else 0}æ¡ï¼‰")
                result = self._translate_single_task(user_command, headers, history=history)
                return [result]
            
            else:
                # ã€è·¯å¾„ Cã€‘å¤åˆæŒ‡ä»¤ï¼Œèµ°æ€»æŒ‡æŒ¥è·¯å¾„
                logger.info("ğŸ¯ ã€è·¯å¾„ Cã€‘å¤åˆæŒ‡ä»¤ï¼Œè°ƒç”¨æ€»æŒ‡æŒ¥æ‹†åˆ†")
                tasks = self._call_coordinator(user_command, history=history)
                
                if not tasks or len(tasks) == 1:
                    # æ€»æŒ‡æŒ¥æ‹†åˆ†å¤±è´¥æˆ–åªæœ‰ä¸€ä¸ªä»»åŠ¡ï¼Œé™çº§åˆ°è·¯å¾„ B
                    logger.info("é™çº§ä¸ºå•ä¸€æŒ‡ä»¤å¤„ç†ï¼ˆå¸¦ historyï¼‰")
                    result = self._translate_single_task(user_command, headers, history=history)
                    return [result]
                
                # â­ï¸ è¿”å›å­ä»»åŠ¡åˆ—è¡¨ï¼Œè®©ä¸Šå±‚ï¼ˆWebSocketï¼‰æ§åˆ¶ç¿»è¯‘èŠ‚å¥å’Œå®æ—¶æ˜¾ç¤º
                logger.info(f"ğŸ”„ å·²æ‹†åˆ†ä¸º {len(tasks)} ä¸ªå­ä»»åŠ¡")
                from ..models.ai_response import create_task_list_response
                return [create_task_list_response(tasks)]  # è¿”å›åŒ…å«ä»»åŠ¡åˆ—è¡¨çš„ AIResponse
            
        except Exception as e:
            error_str = str(e)
            
            # â­ï¸ å¦‚æœæ˜¯429é”™è¯¯ï¼Œç›´æ¥æŠ›å‡ºè®©ä¸Šå±‚ï¼ˆWebSocketï¼‰å¤„ç†é‡è¯•
            if "429" in error_str or "rate_limit" in error_str.lower():
                logger.warning(f"â³ æ£€æµ‹åˆ°429é™æµé”™è¯¯ï¼ŒæŠ›å‡ºå¼‚å¸¸è§¦å‘é‡è¯•")
                raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
            
            # å…¶ä»–é”™è¯¯ï¼Œè¿”å›é”™è¯¯ç»“æœ
            logger.error(f"translate() ä¸»æ–¹æ³•å¤±è´¥: {e}")
            return [create_error_response(
                f"æŒ‡ä»¤ç¿»è¯‘å¤±è´¥: {str(e)}",
                error_code="TRANSLATE_FAILED"
            )]


# åˆ›å»ºå…¨å±€ç¿»è¯‘å™¨å®ä¾‹ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
_translator_instance = None

def get_translator() -> AITranslator:
    """è·å–AIç¿»è¯‘å™¨å•ä¾‹"""
    global _translator_instance
    if _translator_instance is None:
        _translator_instance = AITranslator()
    return _translator_instance

