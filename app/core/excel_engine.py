"""
Excelæ“ä½œå¼•æ“ - ä½¿ç”¨Pandasæ‰§è¡Œå®é™…çš„è¡¨æ ¼æ“ä½œ
è¿™ä¸ªæ¨¡å—æ˜¯"åŒæ‰‹"ï¼Œåªè´Ÿè´£æ‰§è¡Œï¼Œä¸è´Ÿè´£ç†è§£

Author: TJxiaobao
License: MIT
"""
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any, Optional
import logging
from difflib import get_close_matches  # v0.1.0: ç”¨äºæ¨¡ç³ŠåŒ¹é…åˆ—å

from ..utils.helpers import convert_value
from ..config.settings import config

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ExcelEngine:
    """Excelæ“ä½œå¼•æ“"""
    
    def __init__(self, file_path: str):
        """
        åˆå§‹åŒ–å¼•æ“
        Args:
            file_path: Excelæ–‡ä»¶è·¯å¾„
        """
        self.file_path = Path(file_path)
        self.df = pd.read_excel(file_path)
        self.original_df = self.df.copy()  # ä¿ç•™åŸå§‹æ•°æ®å‰¯æœ¬
        self.execution_log = []  # æ“ä½œæ—¥å¿—
        
        logger.info(f"å·²åŠ è½½æ–‡ä»¶: {file_path}")
        logger.info(f"è¡Œæ•°: {len(self.df)}, åˆ—æ•°: {len(self.df.columns)}")
        logger.info(f"åˆ—å: {list(self.df.columns)}")
    
    @staticmethod
    def _convert_value(value: Any) -> Any:
        """æ™ºèƒ½ç±»å‹è½¬æ¢ï¼ˆä½¿ç”¨å·¥å…·ç±»ï¼‰"""
        return convert_value(value)
    
    def _generate_column_not_found_error(self, column_name: str) -> Dict:
        """
        ç”Ÿæˆåˆ—ä¸å­˜åœ¨æ—¶çš„å‹å¥½é”™è¯¯ä¿¡æ¯ï¼ˆå¸¦æ¨¡ç³ŠåŒ¹é…å»ºè®®ï¼‰
        Args:
            column_name: ç”¨æˆ·è¾“å…¥çš„åˆ—å
        Returns:
            åŒ…å«é”™è¯¯å’Œå»ºè®®çš„å­—å…¸
        """
        # ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…æ‰¾ç›¸ä¼¼çš„åˆ—å
        similar_columns = get_close_matches(column_name, self.df.columns, n=3, cutoff=0.6)
        
        error_msg = f"âŒ åˆ— '{column_name}' ä¸å­˜åœ¨"
        
        if similar_columns:
            suggestion = f"ğŸ’¡ **å»ºè®®**ï¼šæ‚¨æ˜¯å¦æƒ³æ“ä½œä»¥ä¸‹åˆ—ï¼Ÿ\n"
            suggestion += "\n".join([f"  â€¢ {col}" for col in similar_columns])
            suggestion += f"\n\nå½“å‰è¡¨æ ¼çš„æ‰€æœ‰åˆ—ï¼š{', '.join(self.df.columns[:5])}{'...' if len(self.df.columns) > 5 else ''}"
        else:
            suggestion = f"ğŸ’¡ **å»ºè®®**ï¼š\nâ€¢ å½“å‰è¡¨æ ¼çš„åˆ—ï¼š{', '.join(self.df.columns)}\nâ€¢ è¯·æ£€æŸ¥åˆ—åæ‹¼å†™å’Œå¤§å°å†™"
        
        return {
            "success": False,
            "error": error_msg,
            "suggestion": suggestion
        }
    
    def get_headers(self) -> List[str]:
        """è·å–æ‰€æœ‰åˆ—å"""
        return list(self.df.columns)
    
    def get_preview(self, rows: int = 5) -> Dict:
        """è·å–æ•°æ®é¢„è§ˆ"""
        return {
            "headers": self.get_headers(),
            "total_rows": len(self.df),
            "preview_data": self.df.head(rows).to_dict(orient='records')
        }
    
    def set_column_value(self, column: str, value: Any) -> Dict:
        """
        ç»™æ•´åˆ—èµ‹å€¼
        Args:
            column: åˆ—å
            value: è¦è®¾ç½®çš„å€¼
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column not in self.df.columns:
            return self._generate_column_not_found_error(column)
        
        try:
            # æ™ºèƒ½ç±»å‹è½¬æ¢
            value = self._convert_value(value)
            affected_rows = len(self.df)
            self.df[column] = value
            
            log_msg = f"âœ… å·²å°†'{column}'åˆ—çš„æ‰€æœ‰ {affected_rows} è¡Œè®¾ç½®ä¸º: {value}"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": affected_rows
            }
        except Exception as e:
            error_msg = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def set_by_condition(
        self, 
        condition_column: str,
        condition_value: Any,
        target_column: str,
        target_value: Any,
        match_type: str = "exact"  # exact, startswith, contains
    ) -> Dict:
        """
        æ ¹æ®æ¡ä»¶ç»™æŒ‡å®šåˆ—èµ‹å€¼
        Args:
            condition_column: æ¡ä»¶åˆ—å
            condition_value: æ¡ä»¶å€¼
            target_column: ç›®æ ‡åˆ—å
            target_value: è¦è®¾ç½®çš„å€¼
            match_type: åŒ¹é…ç±»å‹ (exact/startswith/contains)
        Returns:
            æ‰§è¡Œç»“æœ
        """
        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        if condition_column not in self.df.columns:
            return {
                "success": False, 
                "error": f"æ¡ä»¶åˆ—'{condition_column}'ä¸å­˜åœ¨"
            }
        if target_column not in self.df.columns:
            return {
                "success": False,
                "error": f"ç›®æ ‡åˆ—'{target_column}'ä¸å­˜åœ¨"
            }
        
        try:
            # æ™ºèƒ½ç±»å‹è½¬æ¢
            condition_value = self._convert_value(condition_value)
            target_value = self._convert_value(target_value)
            # æ ¹æ®åŒ¹é…ç±»å‹åˆ›å»ºæ¡ä»¶
            if match_type == "exact":
                mask = self.df[condition_column] == condition_value
                condition_desc = f"'{condition_column}' == '{condition_value}'"
            elif match_type == "startswith":
                mask = self.df[condition_column].astype(str).str.startswith(str(condition_value))
                condition_desc = f"'{condition_column}'ä»¥'{condition_value}'å¼€å¤´"
            elif match_type == "contains":
                mask = self.df[condition_column].astype(str).str.contains(str(condition_value))
                condition_desc = f"'{condition_column}'åŒ…å«'{condition_value}'"
            else:
                return {"success": False, "error": f"ä¸æ”¯æŒçš„åŒ¹é…ç±»å‹: {match_type}"}
            
            # æ‰§è¡Œèµ‹å€¼
            affected_rows = mask.sum()
            if affected_rows == 0:
                # æä¾›å¯ç”¨çš„å€¼åˆ—è¡¨ï¼Œå¸®åŠ©ç”¨æˆ·å’Œ AI ç†è§£ä¸ºä»€ä¹ˆåŒ¹é…å¤±è´¥
                unique_values = self.df[condition_column].unique().tolist()
                unique_values_str = ", ".join([f"'{v}'" for v in unique_values[:10]])  # åªæ˜¾ç¤ºå‰ 10 ä¸ª
                if len(unique_values) > 10:
                    unique_values_str += f" (è¿˜æœ‰ {len(unique_values) - 10} ä¸ªå€¼)"
                
                log_msg = f"âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è¡Œ (æ¡ä»¶: {condition_desc})"
                suggestion = f"ğŸ’¡ '{condition_column}' åˆ—çš„å¯ç”¨å€¼: {unique_values_str}"
                
                logger.warning(log_msg)
                logger.info(suggestion)
                self.execution_log.append(log_msg)
                self.execution_log.append(suggestion)
                
                return {
                    "success": False,  # æ”¹ä¸º Falseï¼Œå› ä¸ºæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•è¡Œåº”è¯¥è§†ä¸ºå¤±è´¥
                    "error": log_msg,
                    "suggestion": suggestion,
                    "affected_rows": 0
                }
            
            self.df.loc[mask, target_column] = target_value
            
            # è®°å½•å—å½±å“çš„è¡Œå·
            affected_indices = self.df[mask].index.tolist()
            
            log_msg = (
                f"âœ… å·²ä¿®æ”¹ {affected_rows} è¡Œ\n"
                f"   æ¡ä»¶: {condition_desc}\n"
                f"   æ“ä½œ: '{target_column}' â†’ {target_value}\n"
                f"   è¡Œå·: {affected_indices[:10]}"  # åªæ˜¾ç¤ºå‰10ä¸ªè¡Œå·
            )
            if len(affected_indices) > 10:
                log_msg += f" ... (è¿˜æœ‰{len(affected_indices) - 10}è¡Œ)"
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": affected_rows,
                "affected_indices": affected_indices[:100]  # æœ€å¤šè¿”å›100ä¸ªè¡Œå·
            }
            
        except Exception as e:
            error_msg = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def copy_column(self, source_column: str, target_column: str) -> Dict:
        """
        å¤åˆ¶åˆ—
        Args:
            source_column: æºåˆ—å
            target_column: ç›®æ ‡åˆ—å
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if source_column not in self.df.columns:
            return {"success": False, "error": f"æºåˆ—'{source_column}'ä¸å­˜åœ¨"}
        if target_column not in self.df.columns:
            return {"success": False, "error": f"ç›®æ ‡åˆ—'{target_column}'ä¸å­˜åœ¨"}
        
        try:
            self.df[target_column] = self.df[source_column]
            affected_rows = len(self.df)
            
            log_msg = f"âœ… å·²å°†'{source_column}'çš„å€¼å¤åˆ¶åˆ°'{target_column}' ({affected_rows}è¡Œ)"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": affected_rows
            }
        except Exception as e:
            error_msg = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def add_column(self, column_name: str, default_value: Any = None) -> Dict:
        """
        æ–°å¢åˆ—
        Args:
            column_name: æ–°åˆ—å
            default_value: é»˜è®¤å€¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºç©ºï¼‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column_name in self.df.columns:
            return {"success": False, "error": f"åˆ—'{column_name}'å·²å­˜åœ¨"}
        
        try:
            # æ·»åŠ æ–°åˆ—ï¼Œé»˜è®¤å€¼ä¸º None æˆ–ç”¨æˆ·æŒ‡å®šçš„å€¼
            converted_value = self._convert_value(default_value) if default_value is not None else None
            self.df[column_name] = converted_value
            
            log_msg = f"âœ… å·²æ–°å¢åˆ—'{column_name}'"
            if default_value is not None:
                log_msg += f"ï¼Œé»˜è®¤å€¼ï¼š{default_value}"
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            return {
                "success": True,
                "message": log_msg,
                "column_name": column_name,
                "default_value": default_value
            }
        except Exception as e:
            error_msg = f"æ–°å¢åˆ—å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def delete_column(self, column_name: str) -> Dict:
        """
        åˆ é™¤åˆ—
        Args:
            column_name: è¦åˆ é™¤çš„åˆ—å
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column_name not in self.df.columns:
            return self._generate_column_not_found_error(column_name)
        
        try:
            self.df = self.df.drop(columns=[column_name])
            
            log_msg = f"âœ… å·²åˆ é™¤åˆ—'{column_name}'"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            return {
                "success": True,
                "message": log_msg,
                "column_name": column_name
            }
        except Exception as e:
            error_msg = f"åˆ é™¤åˆ—å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def set_by_mapping(
        self,
        condition_column: str,
        target_column: str,
        mapping: dict,
        match_type: str = "exact"
    ) -> Dict:
        """
        æ ¹æ®æ˜ å°„è¡¨æ‰¹é‡è®¾ç½®å€¼
        Args:
            condition_column: æ¡ä»¶åˆ—å
            target_column: ç›®æ ‡åˆ—å
            mapping: æ˜ å°„å…³ç³» {æ¡ä»¶å€¼: ç›®æ ‡å€¼}ï¼Œä¾‹å¦‚ {"196001": 10, "196002": 20}
            match_type: åŒ¹é…ç±»å‹ (exact/startswith/contains)
        Returns:
            æ‰§è¡Œç»“æœ
        """
        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        if condition_column not in self.df.columns:
            return {
                "success": False,
                "error": f"æ¡ä»¶åˆ—'{condition_column}'ä¸å­˜åœ¨"
            }
        if target_column not in self.df.columns:
            return {
                "success": False,
                "error": f"ç›®æ ‡åˆ—'{target_column}'ä¸å­˜åœ¨"
            }
        
        if not mapping or not isinstance(mapping, dict):
            return {
                "success": False,
                "error": "æ˜ å°„è¡¨ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯"
            }
        
        try:
            total_affected = 0
            details = []
            
            for condition_value, target_value in mapping.items():
                # æ™ºèƒ½ç±»å‹è½¬æ¢
                condition_value = self._convert_value(condition_value)
                target_value = self._convert_value(target_value)
                
                # æ ¹æ®åŒ¹é…ç±»å‹åˆ›å»ºæ¡ä»¶
                if match_type == "exact":
                    mask = self.df[condition_column] == condition_value
                elif match_type == "startswith":
                    mask = self.df[condition_column].astype(str).str.startswith(str(condition_value))
                elif match_type == "contains":
                    mask = self.df[condition_column].astype(str).str.contains(str(condition_value))
                else:
                    return {"success": False, "error": f"ä¸æ”¯æŒçš„åŒ¹é…ç±»å‹: {match_type}"}
                
                # æ‰§è¡Œèµ‹å€¼
                affected = mask.sum()
                if affected > 0:
                    self.df.loc[mask, target_column] = target_value
                    total_affected += affected
                    details.append(f"    '{condition_value}' â†’ {target_value} ({affected}è¡Œ)")
                else:
                    details.append(f"    '{condition_value}' â†’ {target_value} (0è¡Œï¼Œæœªæ‰¾åˆ°åŒ¹é…)")
            
            # æ„å»ºæ—¥å¿—æ¶ˆæ¯
            log_msg = (
                f"âœ… æ‰¹é‡æ˜ å°„å®Œæˆï¼Œå…±ä¿®æ”¹ {total_affected} è¡Œ\n"
                f"   æ¡ä»¶åˆ—: '{condition_column}'\n"
                f"   ç›®æ ‡åˆ—: '{target_column}'\n"
                f"   æ˜ å°„è§„åˆ™:\n" + "\n".join(details)
            )
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": total_affected,
                "mapping_count": len(mapping)
            }
            
        except Exception as e:
            error_msg = f"æ‰§è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def get_summary(self, column: str, top_n: int = 10) -> Dict:
        """
        ç»Ÿè®¡æŸåˆ—çš„æ•°æ®åˆ†å¸ƒæƒ…å†µ
        Args:
            column: è¦ç»Ÿè®¡çš„åˆ—å
            top_n: è¿”å›å‰Nä¸ªæœ€å¸¸è§çš„å€¼ï¼ˆé»˜è®¤10ï¼‰
        Returns:
            ç»Ÿè®¡ç»“æœ
        """
        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        if column not in self.df.columns:
            return {
                "success": False,
                "error": f"åˆ— '{column}' ä¸å­˜åœ¨"
            }
        
        try:
            # ç»Ÿè®¡å„å€¼çš„æ•°é‡
            value_counts = self.df[column].value_counts()
            
            # æ„å»ºç»Ÿè®¡ä¿¡æ¯
            summary_lines = []
            total_count = len(self.df)
            non_null_count = self.df[column].notna().sum()
            null_count = total_count - non_null_count
            
            # å–å‰Nä¸ª
            top_values = value_counts.head(top_n)
            
            summary_lines.append(f"ğŸ“Š åˆ— '{column}' ç»Ÿè®¡ç»“æœ:")
            summary_lines.append(f"   æ€»è¡Œæ•°: {total_count}")
            summary_lines.append(f"   æœ‰æ•ˆæ•°æ®: {non_null_count}")
            if null_count > 0:
                summary_lines.append(f"   ç©ºå€¼: {null_count}")
            summary_lines.append(f"\n   æ•°æ®åˆ†å¸ƒï¼ˆå‰{min(top_n, len(top_values))}é¡¹ï¼‰:")
            
            for value, count in top_values.items():
                percentage = (count / total_count) * 100
                summary_lines.append(f"     â€¢ '{value}': {count} æ¡ ({percentage:.1f}%)")
            
            # å¦‚æœè¿˜æœ‰å…¶ä»–å€¼
            if len(value_counts) > top_n:
                other_count = value_counts[top_n:].sum()
                other_percentage = (other_count / total_count) * 100
                summary_lines.append(f"     â€¢ å…¶ä»–: {other_count} æ¡ ({other_percentage:.1f}%)")
            
            log_msg = "\n".join(summary_lines)
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            # è¿”å›ç»“æ„åŒ–æ•°æ®
            return {
                "success": True,
                "message": log_msg,
                "is_analysis": True,  # â­ï¸ æ ‡è®°ä¸ºåˆ†æç±»å·¥å…·ï¼Œä¸éœ€è¦ä¿å­˜æ–‡ä»¶
                "column": column,
                "total_rows": total_count,
                "non_null_count": non_null_count,
                "null_count": null_count,
                "value_counts": {str(k): int(v) for k, v in top_values.items()},
                "unique_values": len(value_counts)
            }
            
        except Exception as e:
            error_msg = f"ç»Ÿè®¡å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def perform_math(
        self,
        target_column: str,
        source_column_1: str,
        operator: str,
        source_column_2_or_number: str,
        round_to: int = None
    ) -> Dict:
        """
        æ‰§è¡Œæ•°å­¦è®¡ç®—
        Args:
            target_column: ç›®æ ‡åˆ—åï¼ˆç»“æœå­˜å‚¨ä½ç½®ï¼‰
            source_column_1: ç¬¬ä¸€ä¸ªæ“ä½œæ•°åˆ—å
            operator: è¿ç®—ç¬¦ (add/subtract/multiply/divide)
            source_column_2_or_number: ç¬¬äºŒä¸ªæ“ä½œæ•°ï¼ˆåˆ—åæˆ–æ•°å­—ï¼‰
            round_to: ä¿ç•™å°æ•°ä½æ•°ï¼ˆå¯é€‰ï¼‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        import pandas as pd
        import numpy as np
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªåˆ—æ˜¯å¦å­˜åœ¨
        if source_column_1 not in self.df.columns:
            return self._generate_column_not_found_error(source_column_1)
        
        try:
            # â­ï¸ æ™ºèƒ½æ£€æŸ¥ï¼šç¬¬ä¸€ä¸ªåˆ—æ˜¯å¦å…¨éƒ¨ä¸ºæ–‡æœ¬
            col_1_numeric = pd.to_numeric(self.df[source_column_1], errors='coerce')
            non_numeric_count_1 = col_1_numeric.isna().sum()
            total_count = len(self.df)
            
            # å¦‚æœè¶…è¿‡50%æ— æ³•è½¬æ¢ï¼Œå¾ˆå¯èƒ½æ˜¯æ–‡æœ¬åˆ—
            if non_numeric_count_1 > total_count * 0.5:
                sample_values = self.df[source_column_1].head(3).tolist()
                return {
                    "success": False,
                    "error": f"âŒ åˆ— '{source_column_1}' ä¸»è¦åŒ…å«æ–‡æœ¬ï¼Œæ— æ³•è¿›è¡Œæ•°å­¦è¿ç®—",
                    "suggestion": f"ğŸ’¡ **å»ºè®®**ï¼š\nâ€¢ è¯¥åˆ—çš„æ ·æœ¬å€¼ï¼š{sample_values}\nâ€¢ å¦‚æœåŒ…å«æ•°å­—ï¼Œè¯·å…ˆä½¿ç”¨'æŸ¥æ‰¾æ›¿æ¢'æ¸…ç†ç‰¹æ®Šå­—ç¬¦\nâ€¢ æˆ–è€…é€‰æ‹©ä¸€ä¸ªçº¯æ•°å­—åˆ—è¿›è¡Œè®¡ç®—"
                }
            
            # å‡†å¤‡ç¬¬ä¸€ä¸ªæ“ä½œæ•°ï¼ˆå°†éæ•°å­—è½¬ä¸º0ï¼‰
            col_1_data = col_1_numeric.fillna(0)
            
            # å‡†å¤‡ç¬¬äºŒä¸ªæ“ä½œæ•°
            is_column = source_column_2_or_number in self.df.columns
            
            if is_column:
                # â­ï¸ æ™ºèƒ½æ£€æŸ¥ï¼šç¬¬äºŒä¸ªåˆ—æ˜¯å¦å…¨éƒ¨ä¸ºæ–‡æœ¬
                col_2_numeric = pd.to_numeric(self.df[source_column_2_or_number], errors='coerce')
                non_numeric_count_2 = col_2_numeric.isna().sum()
                
                # å¦‚æœè¶…è¿‡50%æ— æ³•è½¬æ¢ï¼Œå¾ˆå¯èƒ½æ˜¯æ–‡æœ¬åˆ—
                if non_numeric_count_2 > total_count * 0.5:
                    sample_values = self.df[source_column_2_or_number].head(3).tolist()
                    return {
                        "success": False,
                        "error": f"âŒ åˆ— '{source_column_2_or_number}' ä¸»è¦åŒ…å«æ–‡æœ¬ï¼Œæ— æ³•è¿›è¡Œæ•°å­¦è¿ç®—",
                        "suggestion": f"ğŸ’¡ **å»ºè®®**ï¼š\nâ€¢ è¯¥åˆ—çš„æ ·æœ¬å€¼ï¼š{sample_values}\nâ€¢ å¦‚æœåŒ…å«æ•°å­—ï¼Œè¯·å…ˆä½¿ç”¨'æŸ¥æ‰¾æ›¿æ¢'æ¸…ç†ç‰¹æ®Šå­—ç¬¦\nâ€¢ æˆ–è€…é€‰æ‹©ä¸€ä¸ªçº¯æ•°å­—åˆ—è¿›è¡Œè®¡ç®—"
                    }
                
                # å¦‚æœæ˜¯åˆ—å
                col_2_data = col_2_numeric.fillna(0)
                operand_desc = f"åˆ— '{source_column_2_or_number}'"
            else:
                # å¦‚æœæ˜¯æ•°å­—
                try:
                    col_2_data = float(self._convert_value(source_column_2_or_number))
                    non_numeric_count_2 = 0
                    operand_desc = f"æ•°å­— {col_2_data}"
                except:
                    return {
                        "success": False,
                        "error": f"âŒ '{source_column_2_or_number}' æ—¢ä¸æ˜¯æœ‰æ•ˆçš„åˆ—åä¹Ÿä¸æ˜¯æœ‰æ•ˆçš„æ•°å­—",
                        "suggestion": f"ğŸ’¡ **å»ºè®®**ï¼š\nâ€¢ æ£€æŸ¥åˆ—åæ˜¯å¦æ­£ç¡®ï¼ˆå½“å‰è¡¨æ ¼åˆ—åï¼š{', '.join(self.df.columns[:5])}{'...' if len(self.df.columns) > 5 else ''}ï¼‰\nâ€¢ å¦‚æœæ˜¯æ•°å­—ï¼Œè¯·ç¡®ä¿æ²¡æœ‰å¤šä½™çš„ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦"
                    }
            
            # æ‰§è¡Œè¿ç®—
            if operator == "add":
                result = col_1_data + col_2_data
                op_symbol = "+"
            elif operator == "subtract":
                result = col_1_data - col_2_data
                op_symbol = "-"
            elif operator == "multiply":
                result = col_1_data * col_2_data
                op_symbol = "Ã—"
            elif operator == "divide":
                result = col_1_data / col_2_data
                # å¤„ç†é™¤é›¶
                result = result.replace([np.inf, -np.inf], 0)
                op_symbol = "Ã·"
            else:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„è¿ç®—ç¬¦: {operator}"
                }
            
            # å››èˆäº”å…¥
            if round_to is not None:
                result = result.round(int(round_to))
                round_desc = f"ï¼Œä¿ç•™{round_to}ä½å°æ•°"
            else:
                round_desc = ""
            
            # ä¿å­˜ç»“æœ
            is_new_column = target_column not in self.df.columns
            self.df[target_column] = result
            
            # æ„å»ºæ—¥å¿—
            action = "åˆ›å»º" if is_new_column else "æ›´æ–°"
            log_msg = f"âœ… å·²{action}åˆ— '{target_column}' = '{source_column_1}' {op_symbol} {operand_desc}{round_desc}"
            
            # æ·»åŠ è­¦å‘Šä¿¡æ¯
            warnings = []
            if non_numeric_count_1 > 0:
                warnings.append(f"âš ï¸  '{source_column_1}' åˆ—ä¸­æœ‰ {non_numeric_count_1} ä¸ªéæ•°å­—å€¼å·²è§†ä¸º 0")
            if is_column and non_numeric_count_2 > 0:
                warnings.append(f"âš ï¸  '{source_column_2_or_number}' åˆ—ä¸­æœ‰ {non_numeric_count_2} ä¸ªéæ•°å­—å€¼å·²è§†ä¸º 0")
            
            if warnings:
                log_msg += "\n" + "\n".join(warnings)
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": len(self.df)
            }
            
        except Exception as e:
            error_msg = f"âŒ æ•°å­¦è®¡ç®—å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "suggestion": "ğŸ’¡ **å»ºè®®**ï¼šè¯·æ£€æŸ¥åˆ—åæ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•ç®€åŒ–è®¡ç®—æ­¥éª¤"
            }
    
    def trim_whitespace(self, column: str) -> Dict:
        """
        æ¸…ç†åˆ—ä¸­çš„é¦–å°¾ç©ºæ ¼
        Args:
            column: åˆ—å
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column not in self.df.columns:
            return self._generate_column_not_found_error(column)
        
        try:
            # æ¸…ç†ç©ºæ ¼
            self.df[column] = self.df[column].astype(str).str.strip()
            
            log_msg = f"âœ… å·²æ¸…ç† '{column}' åˆ—çš„é¦–å°¾ç©ºæ ¼"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": len(self.df)
            }
            
        except Exception as e:
            error_msg = f"æ¸…ç†ç©ºæ ¼å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def fill_missing_values(self, column: str, fill_value: str) -> Dict:
        """
        å¡«å……ç©ºç™½å•å…ƒæ ¼
        Args:
            column: åˆ—å
            fill_value: å¡«å……å€¼
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column not in self.df.columns:
            return {
                "success": False,
                "error": f"åˆ— '{column}' ä¸å­˜åœ¨"
            }
        
        try:
            # ç»Ÿè®¡ç©ºå€¼æ•°é‡
            null_count = self.df[column].isna().sum()
            
            # å¡«å……ç©ºå€¼
            fill_value = self._convert_value(fill_value)
            self.df[column].fillna(fill_value, inplace=True)
            
            log_msg = f"âœ… å·²å°† '{column}' åˆ—çš„ {null_count} ä¸ªç©ºç™½å•å…ƒæ ¼å¡«å……ä¸º '{fill_value}'"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": null_count
            }
            
        except Exception as e:
            error_msg = f"å¡«å……ç©ºå€¼å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def find_and_replace(
        self,
        column: str,
        find_text: str,
        replace_text: str
    ) -> Dict:
        """
        æŸ¥æ‰¾å¹¶æ›¿æ¢æ–‡æœ¬
        Args:
            column: åˆ—å
            find_text: è¦æŸ¥æ‰¾çš„æ–‡æœ¬
            replace_text: æ›¿æ¢æˆçš„æ–‡æœ¬
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column not in self.df.columns:
            return {
                "success": False,
                "error": f"åˆ— '{column}' ä¸å­˜åœ¨"
            }
        
        try:
            # ç»Ÿè®¡æ›¿æ¢æ•°é‡
            find_text = str(find_text)
            replace_text = str(replace_text)
            
            # ç»Ÿè®¡åŒ…å«ç›®æ ‡æ–‡æœ¬çš„è¡Œæ•°
            contains_count = self.df[column].astype(str).str.contains(find_text, na=False).sum()
            
            # æ‰§è¡Œæ›¿æ¢
            self.df[column] = self.df[column].astype(str).str.replace(find_text, replace_text, regex=False)
            
            log_msg = f"âœ… å·²åœ¨ '{column}' åˆ—ä¸­å°† '{find_text}' æ›¿æ¢ä¸º '{replace_text}' ({contains_count} å¤„)"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": contains_count
            }
            
        except Exception as e:
            error_msg = f"æŸ¥æ‰¾æ›¿æ¢å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def concatenate_columns(
        self,
        target_column: str,
        source_columns: List[str],
        delimiter: str = " "
    ) -> Dict:
        """
        åˆå¹¶å¤šåˆ—ä¸ºä¸€åˆ—
        Args:
            target_column: æ–°åˆ—åç§°
            source_columns: è¦åˆå¹¶çš„æºåˆ—ååˆ—è¡¨
            delimiter: è¿æ¥ç¬¦ï¼ˆé»˜è®¤ä¸ºç©ºæ ¼ï¼‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        # æ£€æŸ¥æºåˆ—æ˜¯å¦å­˜åœ¨
        missing_cols = [col for col in source_columns if col not in self.df.columns]
        if missing_cols:
            return {
                "success": False,
                "error": f"ä»¥ä¸‹åˆ—ä¸å­˜åœ¨: {', '.join(missing_cols)}"
            }
        
        try:
            # å¥å£®æ€§ï¼šç¡®ä¿æ‰€æœ‰æºåˆ—éƒ½æ˜¯å­—ç¬¦ä¸²
            self.df[target_column] = self.df[source_columns].astype(str).agg(delimiter.join, axis=1)
            
            log_msg = f"âœ… å·²å°† {len(source_columns)} åˆ—åˆå¹¶ä¸º '{target_column}'ï¼Œä½¿ç”¨ '{delimiter}' è¿æ¥"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": len(self.df)
            }
            
        except Exception as e:
            error_msg = f"åˆ—åˆå¹¶å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def extract_date_part(
        self,
        source_column: str,
        target_column: str,
        part_to_extract: str
    ) -> Dict:
        """
        ä»æ—¥æœŸåˆ—æå–ç»„ä»¶ï¼ˆå¹´/æœˆ/æ—¥/æ˜ŸæœŸ/å­£åº¦ï¼‰
        Args:
            source_column: æºæ—¥æœŸåˆ—å
            target_column: ç›®æ ‡åˆ—å
            part_to_extract: è¦æå–çš„éƒ¨åˆ†ï¼ˆyear/month/day/weekday/quarterï¼‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if source_column not in self.df.columns:
            return self._generate_column_not_found_error(source_column)
        
        try:
            # å…³é”®ï¼šå¥å£®åœ°è½¬ä¸ºæ—¥æœŸï¼Œæ— æ³•è§£æçš„å˜ä¸º NaT
            date_series = pd.to_datetime(self.df[source_column], errors='coerce')
            
            # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨æ— æ³•è§£æ
            null_count = date_series.isnull().sum()
            if date_series.isnull().all():
                return {
                    "success": False,
                    "error": f"æ— æ³•å°† '{source_column}' åˆ—è§£æä¸ºæ—¥æœŸ"
                }
            
            # æå–å¯¹åº”éƒ¨åˆ†
            if part_to_extract == 'year':
                self.df[target_column] = date_series.dt.year
                part_desc = "å¹´ä»½"
            elif part_to_extract == 'month':
                self.df[target_column] = date_series.dt.month
                part_desc = "æœˆä»½"
            elif part_to_extract == 'day':
                self.df[target_column] = date_series.dt.day
                part_desc = "æ—¥æœŸ"
            elif part_to_extract == 'weekday':
                # ä¸­æ–‡æ˜ŸæœŸå‡ æ›´å‹å¥½
                weekdays_chinese = ['æ˜ŸæœŸä¸€', 'æ˜ŸæœŸäºŒ', 'æ˜ŸæœŸä¸‰', 'æ˜ŸæœŸå››', 'æ˜ŸæœŸäº”', 'æ˜ŸæœŸå…­', 'æ˜ŸæœŸæ—¥']
                self.df[target_column] = date_series.dt.weekday.apply(
                    lambda x: weekdays_chinese[int(x)] if pd.notna(x) else None
                )
                part_desc = "æ˜ŸæœŸå‡ "
            elif part_to_extract == 'quarter':
                self.df[target_column] = date_series.dt.quarter
                part_desc = "å­£åº¦"
            else:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„æ—¥æœŸéƒ¨åˆ†: {part_to_extract}"
                }
            
            log_msg = f"âœ… å·²ä» '{source_column}' æå– {part_desc} åˆ° '{target_column}'"
            if null_count > 0:
                log_msg += f"\nâš ï¸  {null_count} ä¸ªå•å…ƒæ ¼æ— æ³•è§£æä¸ºæ—¥æœŸ"
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": len(self.df)
            }
            
        except Exception as e:
            error_msg = f"æ—¥æœŸæå–å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def group_by_aggregate(
        self,
        group_by_column: str,
        agg_column: str,
        agg_func: str
    ) -> Dict:
        """
        åˆ†ç»„èšåˆç»Ÿè®¡ï¼ˆåªç»Ÿè®¡ï¼Œä¸ä¿®æ”¹è¡¨æ ¼ï¼‰
        Args:
            group_by_column: åˆ†ç»„åˆ—å
            agg_column: èšåˆè®¡ç®—çš„åˆ—å
            agg_func: èšåˆå‡½æ•°ï¼ˆmean/sum/countï¼‰
        Returns:
            æ‰§è¡Œç»“æœï¼ˆåŒ…å«ç»Ÿè®¡æ–‡æœ¬ï¼‰
        """
        # æ£€æŸ¥åˆ—æ˜¯å¦å­˜åœ¨
        if group_by_column not in self.df.columns:
            return {
                "success": False,
                "error": f"åˆ†ç»„åˆ— '{group_by_column}' ä¸å­˜åœ¨"
            }
        if agg_column not in self.df.columns:
            return {
                "success": False,
                "error": f"èšåˆåˆ— '{agg_column}' ä¸å­˜åœ¨"
            }
        
        try:
            # å¥å£®æ€§ï¼šå¯¹äºæ•°å€¼èšåˆï¼Œç¡®ä¿åˆ—æ˜¯æ•°å­—ç±»å‹
            if agg_func in ['mean', 'sum']:
                self.df[agg_column] = pd.to_numeric(self.df[agg_column], errors='coerce').fillna(0)
            
            # æ‰§è¡Œåˆ†ç»„èšåˆ
            grouped_data = self.df.groupby(group_by_column)[agg_column].agg(agg_func)
            
            # æ ¼å¼åŒ–ç»“æœ
            func_name_map = {
                'mean': 'å¹³å‡å€¼',
                'sum': 'æ€»å’Œ',
                'count': 'è®¡æ•°'
            }
            func_desc = func_name_map.get(agg_func, agg_func)
            
            result_text = f"ğŸ“Š æŒ‰ '{group_by_column}' åˆ†ç»„ï¼Œ'{agg_column}' çš„ {func_desc}ï¼š\n"
            result_text += "=" * 40 + "\n"
            result_text += grouped_data.to_string()
            
            logger.info(f"åˆ†ç»„èšåˆå®Œæˆ: {group_by_column} -> {agg_column} ({agg_func})")
            self.execution_log.append(result_text)
            
            # é‡è¦ï¼šæ ‡è®°ä¸ºåˆ†æç±»å·¥å…·ï¼ˆä¸ä¿®æ”¹è¡¨æ ¼ï¼Œä¸ä¿å­˜ï¼‰
            return {
                "success": True,
                "message": result_text,
                "is_analysis": True  # ç‰¹æ®Šæ ‡è®°
            }
            
        except Exception as e:
            error_msg = f"åˆ†ç»„èšåˆå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def split_column(
        self,
        source_column: str,
        delimiter: str,
        new_column_names: Optional[List[str]] = None
    ) -> Dict:
        """
        æ‹†åˆ†åˆ—ï¼ˆæŒ‰åˆ†éš”ç¬¦å°†ä¸€åˆ—æ‹†åˆ†ä¸ºå¤šåˆ—ï¼‰
        Args:
            source_column: è¦æ‹†åˆ†çš„æºåˆ—å
            delimiter: åˆ†éš”ç¬¦
            new_column_names: å¯é€‰çš„æ–°åˆ—ååˆ—è¡¨ã€‚å¦‚æœæœªæä¾›ï¼Œè‡ªåŠ¨å‘½åä¸º æºåˆ—å_1, æºåˆ—å_2 ç­‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if source_column not in self.df.columns:
            return {
                "success": False,
                "error": f"åˆ— '{source_column}' ä¸å­˜åœ¨"
            }
        
        try:
            # æ‹†åˆ†æˆä¸€ä¸ªä¸´æ—¶çš„ DataFrame
            split_data = self.df[source_column].astype(str).str.split(delimiter, expand=True)
            actual_parts = split_data.shape[1]
            
            warnings = []
            
            # ç¡®å®šæ–°åˆ—å
            if new_column_names:
                if len(new_column_names) < actual_parts:
                    # è¡¥å…¨ç¼ºå¤±çš„åˆ—å
                    original_len = len(new_column_names)
                    new_column_names.extend([f"{source_column}_{i+1}" for i in range(original_len, actual_parts)])
                    warnings.append(f"âš ï¸ å®é™…æ‹†åˆ†äº† {actual_parts} åˆ—ï¼Œæ‚¨æä¾›äº† {original_len} ä¸ªåˆ—åï¼Œå·²è‡ªåŠ¨è¡¥å…¨")
                elif len(new_column_names) > actual_parts:
                    # æˆªæ–­å¤šä½™çš„åˆ—å
                    original_len = len(new_column_names)
                    new_column_names = new_column_names[:actual_parts]
                    warnings.append(f"âš ï¸ å®é™…æ‹†åˆ†äº† {actual_parts} åˆ—ï¼Œä½†æ‚¨æä¾›äº† {original_len} ä¸ªåˆ—åï¼Œå·²æˆªæ–­")
            else:
                new_column_names = [f"{source_column}_{i+1}" for i in range(actual_parts)]
            
            # èµ‹ç»™æ–°çš„åˆ—
            split_data.columns = new_column_names
            self.df = pd.concat([self.df, split_data], axis=1)
            
            log_msg = f"âœ… å·²å°† '{source_column}' åˆ—æŒ‰ '{delimiter}' æ‹†åˆ†ä¸º {len(new_column_names)} åˆ—"
            if warnings:
                log_msg += "\n" + "\n".join(warnings)
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": len(self.df),
                "new_columns": new_column_names
            }
            
        except Exception as e:
            error_msg = f"åˆ—æ‹†åˆ†å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def change_case(
        self,
        column_name: str,
        case_type: str
    ) -> Dict:
        """
        æ›´æ”¹åˆ—çš„å¤§å°å†™
        Args:
            column_name: åˆ—å
            case_type: å¤§å°å†™ç±»å‹ï¼ˆupper/lower/properï¼‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column_name not in self.df.columns:
            return {
                "success": False,
                "error": f"åˆ— '{column_name}' ä¸å­˜åœ¨"
            }
        
        try:
            case_desc_map = {
                'upper': 'å¤§å†™',
                'lower': 'å°å†™',
                'proper': 'é¦–å­—æ¯å¤§å†™'
            }
            
            if case_type == 'upper':
                self.df[column_name] = self.df[column_name].astype(str).str.upper()
            elif case_type == 'lower':
                self.df[column_name] = self.df[column_name].astype(str).str.lower()
            elif case_type == 'proper':
                self.df[column_name] = self.df[column_name].astype(str).str.title()  # Pandas çš„ title() å³ Excel çš„ PROPER()
            else:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„å¤§å°å†™ç±»å‹ '{case_type}'ï¼Œè¯·ä½¿ç”¨ upper/lower/proper"
                }
            
            case_desc = case_desc_map.get(case_type, case_type)
            log_msg = f"âœ… å·²å°† '{column_name}' åˆ—è½¬ä¸º{case_desc}"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": len(self.df)
            }
            
        except Exception as e:
            error_msg = f"å¤§å°å†™è½¬æ¢å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def drop_duplicates(
        self,
        subset_columns: Optional[List[str]] = None
    ) -> Dict:
        """
        åˆ é™¤é‡å¤è¡Œ
        Args:
            subset_columns: ç”¨äºåˆ¤æ–­é‡å¤çš„åˆ—ã€‚å¦‚æœä¸º Noneï¼Œåˆ™åˆ¤æ–­æ‰€æœ‰åˆ—
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            original_count = len(self.df)
            
            # å¦‚æœ subset_columns æ˜¯ç©ºåˆ—è¡¨ï¼ŒPandas ä¼šæŠ¥é”™ï¼Œéœ€è½¬ä¸º None
            subset = subset_columns if subset_columns else None
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            if subset:
                missing_cols = [col for col in subset if col not in self.df.columns]
                if missing_cols:
                    return {
                        "success": False,
                        "error": f"ä»¥ä¸‹åˆ—ä¸å­˜åœ¨: {', '.join(missing_cols)}"
                    }
            
            self.df.drop_duplicates(subset=subset, keep='first', inplace=True)
            self.df.reset_index(drop=True, inplace=True)  # é‡ç½®ç´¢å¼•
            
            new_count = len(self.df)
            deleted_count = original_count - new_count
            
            if subset:
                log_msg = f"âœ… å·²æ ¹æ® {', '.join(subset)} åˆ—åˆ é™¤ {deleted_count} è¡Œé‡å¤æ•°æ®ï¼ˆä¿ç•™é¦–æ¬¡å‡ºç°ï¼‰"
            else:
                log_msg = f"âœ… å·²åˆ é™¤ {deleted_count} è¡Œå®Œå…¨é‡å¤çš„æ•°æ®ï¼ˆä¿ç•™é¦–æ¬¡å‡ºç°ï¼‰"
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "deleted_rows": deleted_count,
                "remaining_rows": new_count
            }
            
        except Exception as e:
            error_msg = f"åˆ é™¤é‡å¤è¡Œå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def sort_by_column(
        self,
        column_name: str,
        ascending: bool = True
    ) -> Dict:
        """
        æŒ‰åˆ—æ’åº
        Args:
            column_name: æ’åºä¾æ®çš„åˆ—å
            ascending: æ˜¯å¦å‡åºï¼ˆTrue=å‡åºï¼ŒFalse=é™åºï¼‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        if column_name not in self.df.columns:
            return {
                "success": False,
                "error": f"åˆ— '{column_name}' ä¸å­˜åœ¨"
            }
        
        try:
            self.df.sort_values(by=column_name, ascending=ascending, inplace=True)
            self.df.reset_index(drop=True, inplace=True)  # é‡ç½®ç´¢å¼•
            
            order_desc = "å‡åº" if ascending else "é™åº"
            log_msg = f"âœ… å·²æŒ‰ '{column_name}' åˆ—{order_desc}æ’åº"
            
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "affected_rows": len(self.df)
            }
            
        except Exception as e:
            error_msg = f"æ’åºå¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
    
    def save(self, output_path: Optional[str] = None) -> str:
        """
        ä¿å­˜ä¿®æ”¹åçš„æ–‡ä»¶
        Args:
            output_path: è¾“å‡ºè·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
        Returns:
            ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
        """
        if output_path is None:
            output_path = str(self.file_path.parent / f"{self.file_path.stem}_modified.xlsx")
        
        self.df.to_excel(output_path, index=False)
        logger.info(f"æ–‡ä»¶å·²ä¿å­˜: {output_path}")
        return output_path
    
    def get_execution_log(self) -> List[str]:
        """è·å–æ‰§è¡Œæ—¥å¿—"""
        return self.execution_log
    
    def reset(self):
        """é‡ç½®åˆ°åŸå§‹çŠ¶æ€"""
        self.df = self.original_df.copy()
        self.execution_log = []
        logger.info("å·²é‡ç½®åˆ°åŸå§‹çŠ¶æ€")

    def get_all_data(self) -> Dict:
        """
        è·å–æ‰€æœ‰æ•°æ®(ç”¨äºå‰ç«¯ Handsontable æ˜¾ç¤º)
        Returns:
            åŒ…å«è¡¨å¤´å’Œæ•°æ®çš„å­—å…¸
        """
        import numpy as np
        import math
        
        def clean_value(val):
            """æ¸…ç†å•ä¸ªå€¼ï¼Œç¡®ä¿JSONå…¼å®¹"""
            # å¤„ç†None
            if val is None:
                return None
            
            # å¤„ç†numpyå’ŒPythonçš„æ•°å€¼ç±»å‹
            if isinstance(val, (np.integer, np.floating)):
                val = val.item()  # è½¬æ¢ä¸ºPythonåŸç”Ÿç±»å‹
            
            # å¤„ç†floatç±»å‹çš„ç‰¹æ®Šå€¼
            if isinstance(val, float):
                if math.isnan(val) or math.isinf(val):
                    return None
            
            return val
        
        # é€è¡Œå¤„ç†æ•°æ®
        cleaned_data = []
        for _, row in self.df.iterrows():
            cleaned_row = [clean_value(val) for val in row]
            cleaned_data.append(cleaned_row)
        
        return {
            "headers": list(self.df.columns),
            "data": cleaned_data
        }

    def update_data(self, data: List[List[Any]]) -> Dict:
        """
        æ›´æ–°æ‰€æœ‰æ•°æ®ï¼ˆä»å‰ç«¯ Handsontable ä¿å­˜ï¼‰
        Args:
            data: äºŒç»´æ•°ç»„æ•°æ®ï¼ˆåŒ…å«è¡¨å¤´ï¼‰
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            if not data or len(data) < 1:
                return {"success": False, "error": "æ•°æ®ä¸ºç©º"}
            
            # ç¬¬ä¸€è¡Œæ˜¯è¡¨å¤´
            headers = data[0]
            rows = data[1:]
            
            # æ›´æ–° DataFrame
            self.df = pd.DataFrame(rows, columns=headers)
            
            # å°è¯•è‡ªåŠ¨æ¨æ–­æ•°æ®ç±»å‹ï¼ˆå¦åˆ™éƒ½æ˜¯å­—ç¬¦ä¸²ï¼‰
            self.df = self.df.infer_objects()
            
            log_msg = f"âœ… å·²æ‰‹åŠ¨æ›´æ–°è¡¨æ ¼æ•°æ® ({len(self.df)} è¡Œ)"
            logger.info(log_msg)
            self.execution_log.append(log_msg)
            
            return {
                "success": True,
                "message": log_msg,
                "total_rows": len(self.df)
            }
        except Exception as e:
            error_msg = f"æ•°æ®æ›´æ–°å¤±è´¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}

    
    def execute_tool(self, tool_name: str, parameters: Dict) -> Dict:
        """
        ç»Ÿä¸€çš„å·¥å…·æ‰§è¡Œæ¥å£ï¼ˆä¾› WebSocket ä½¿ç”¨ï¼‰
        Args:
            tool_name: å·¥å…·åç§°
            parameters: å·¥å…·å‚æ•°
        Returns:
            æ‰§è¡Œç»“æœ
        """
        # è½¬æ¢å‚æ•°ç±»å‹
        if tool_name == "get_summary" and 'top_n' in parameters:
            if isinstance(parameters['top_n'], str):
                parameters['top_n'] = int(parameters['top_n'])
        
        if tool_name == "perform_math" and 'round_to' in parameters:
            if parameters['round_to']:
                parameters['round_to'] = int(parameters['round_to'])
        
        if tool_name == "sort_by_column" and 'ascending' in parameters:
            if isinstance(parameters['ascending'], str):
                parameters['ascending'] = parameters['ascending'].lower() in ['true', '1', 'yes']
        
        # è°ƒç”¨å¯¹åº”çš„æ–¹æ³•
        if tool_name == "set_column_value":
            return self.set_column_value(**parameters)
        elif tool_name == "set_by_condition":
            return self.set_by_condition(**parameters)
        elif tool_name == "copy_column":
            return self.copy_column(**parameters)
        elif tool_name == "set_by_mapping":
            return self.set_by_mapping(**parameters)
        elif tool_name == "get_summary":
            return self.get_summary(**parameters)
        elif tool_name == "perform_math":
            return self.perform_math(**parameters)
        elif tool_name == "trim_whitespace":
            return self.trim_whitespace(**parameters)
        elif tool_name == "fill_missing_values":
            return self.fill_missing_values(**parameters)
        elif tool_name == "find_and_replace":
            return self.find_and_replace(**parameters)
        elif tool_name == "concatenate_columns":
            return self.concatenate_columns(**parameters)
        elif tool_name == "extract_date_part":
            return self.extract_date_part(**parameters)
        elif tool_name == "group_by_aggregate":
            return self.group_by_aggregate(**parameters)
        elif tool_name == "split_column":
            return self.split_column(**parameters)
        elif tool_name == "change_case":
            return self.change_case(**parameters)
        elif tool_name == "drop_duplicates":
            return self.drop_duplicates(**parameters)
        elif tool_name == "sort_by_column":
            return self.sort_by_column(**parameters)
        elif tool_name == "add_column":
            return self.add_column(**parameters)
        elif tool_name == "delete_column":
            return self.delete_column(**parameters)
        else:
            return {
                "success": False,
                "error": f"æœªçŸ¥å·¥å…·: {tool_name}"
            }


# å·¥å…·å‡½æ•°æ˜ å°„ - ä¾›AIè°ƒç”¨
TOOL_FUNCTIONS = {
    "set_column_value": ExcelEngine.set_column_value,
    "set_by_condition": ExcelEngine.set_by_condition,
    "copy_column": ExcelEngine.copy_column,
    "set_by_mapping": ExcelEngine.set_by_mapping,
    "get_summary": ExcelEngine.get_summary,
    "perform_math": ExcelEngine.perform_math,
    "trim_whitespace": ExcelEngine.trim_whitespace,
    "fill_missing_values": ExcelEngine.fill_missing_values,
    "find_and_replace": ExcelEngine.find_and_replace,
    "concatenate_columns": ExcelEngine.concatenate_columns,  # v0.0.4-alpha
    "extract_date_part": ExcelEngine.extract_date_part,      # v0.0.4-alpha
    "group_by_aggregate": ExcelEngine.group_by_aggregate,    # v0.0.4-alpha
    "split_column": ExcelEngine.split_column,                # v0.0.4-beta
    "change_case": ExcelEngine.change_case,                  # v0.0.4-beta
    "drop_duplicates": ExcelEngine.drop_duplicates,          # v0.0.4-beta
    "sort_by_column": ExcelEngine.sort_by_column,            # v0.0.4-beta
    "add_column": ExcelEngine.add_column,                    # v0.0.6
    "delete_column": ExcelEngine.delete_column,                # v0.0.6
}

